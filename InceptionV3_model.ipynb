{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_input() is used to preprocess any given image to extract features of that image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# load_img() is used to load image from file as a pil image\n",
    "# img_to_array() is used to convert pil image instance to a numpy array so that our model can understand/interpret the image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# Model() can be instanciated to include the necessary layers given some input arrays or tensors to output arrays or tensors\n",
    "from tensorflow.keras.models import Model\n",
    "# Pickle is used to serialize and deserialize the python object structure so that any object on python can be pickled and saved to the disk\n",
    "# So pickle.dumb() fuction is used to save object data to the file\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Image Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes document text as arguments\n",
    "# And returns dictonary of image identifiers and corresponding descriptions\n",
    "def read_image_descriptions(filename):\n",
    "    # Open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # Read all the text from the file\n",
    "    text = file.read()\n",
    "    # After reading the file completely close the file\n",
    "    file.close()\n",
    "    \n",
    "    # Initializing a dictionary named image_id_dict\n",
    "    image_id_dict = dict()\n",
    "    \n",
    "    # Incorporating for loop to read each sentence from the text by splitting them on the basis of new line character ('\\n')\n",
    "    for line in text.split('\\n'):\n",
    "        # Splitting each sentence obtained from above on the basis of white space into indivudial words/tokens\n",
    "        # You can also use nltk classes like words_tokenize() to tokenize sentence to words/tokens\n",
    "        tokens = line.split()\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        # Now for each sentence we treat first token as image id and rest of the tokens as image description\n",
    "        image_id, image_description = tokens[0], tokens[1:]\n",
    "        # Remove file extension from the image_id\n",
    "        image_id = image_id.split('.')[0]\n",
    "        # Convert image description tokens back to string\n",
    "        image_description = ' '.join(image_description)\n",
    "        # Create the list if needed\n",
    "        if image_id not in image_id_dict:\n",
    "            image_id_dict[image_id] = list()\n",
    "        # Store description\n",
    "        image_id_dict[image_id].append(image_description)\n",
    "        \n",
    "    return image_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to clean description of image\n",
    "# This function takes dictionary of image_id and description as input\n",
    "def clean_description_text(description):\n",
    "    # Prepare translation table for removing punctuations\n",
    "    # This uses the 3-argument version of str.maketrans with arguments (x, y, z) where 'x' and 'y' must be equal-length strings\n",
    "    # Characters in 'x' are replaced by characters in 'y'.\n",
    "    # 'z' is a string (string.punctuation here) where each character in the string is mapped to None\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    for key, desc_list in description.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            # Get the description at i'th index from all the given five descriptions for that image\n",
    "            desc = desc_list[i]\n",
    "            # Tokenize(grab each words as list) the description by splitting them based on whitespaces\n",
    "            desc = desc.split()\n",
    "            # Convert the words to lower case\n",
    "            desc = [word.lower() for word in desc]\n",
    "            # Remove punctions from each token\n",
    "            # translate() method returns a string where each character is mapped to its corresponding character in the translation table\n",
    "            desc = [word.translate(translator) for word in desc]\n",
    "            # Removing single charactered words\n",
    "            # Removing hanging 's' and 'a'\n",
    "            desc = [word for word in desc if len(word)>1]\n",
    "            # Take only alpahabets containing words and exclude those containing numbers or other special characters\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            # Convert the i'th image description tokens back to string\n",
    "            desc_list[i] = ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save description to file\n",
    "# description argument is a dictionary which contains mapping of image identifiers to the corresponding descriptions\n",
    "# filename argument is the name, we want to give to the file in which we want to save the mapping of image identifiers to cleaned descriptions\n",
    "def save_description(description, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in description.items():\n",
    "        for desc in desc_list:\n",
    "            # Save description of the image preceded by the image identifier\n",
    "            lines.append(key + \" \" + desc)\n",
    "    # Convert all the descriptions list as string into new lines\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of descriptions: 8092\n"
     ]
    }
   ],
   "source": [
    "# Calling the above created functions in a series\n",
    "filename = './Datasets/Flickr8k.token.txt'\n",
    "descriptions = read_image_descriptions(filename)\n",
    "print(f\"Total number of descriptions: {len(descriptions)}\")\n",
    "clean_description_text(descriptions)\n",
    "save_description(descriptions, 'InceptionV3_descriptions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to extract features from each image to the directory\n",
    "def get_image_features(directory):\n",
    "    # Create an instance of the InceptionV3 model\n",
    "    model = InceptionV3()\n",
    "    # Restructuring our InceptionV3 model by removing/Popping off the last layer of the model\n",
    "    # The last layer is used to classify the images. Since we are not classifying images here, we're removing the last layer\n",
    "    model.layers.pop()\n",
    "    # Keras model represents the actual neural network model.\n",
    "    # Keras provides a two mode to create the model, simple and easy to use Sequential API as well as more flexible and advanced Functional API.\n",
    "    # A ANN model can be created by simply calling Sequential() API\n",
    "    # Sequential API is used to create models layer-by-layer\n",
    "    # Functional model, you can define multiple input or output that share layers.\n",
    "    # First, we create an instance for model using Model class and connect to the layers to access input and output to the model\n",
    "    # model.inputs is the input fed to the model and model.layers[-1].output is the output of the last(-1) layer of the model\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    # Print the summary of the model\n",
    "    print(model.summary())\n",
    "    # This empty dictionary will be used to store image features\n",
    "    features = dict()\n",
    "    \n",
    "    # Iterate through each images in given directory using for loop\n",
    "    for file_name in tqdm(os.listdir(directory)):\n",
    "        filename = f\"{directory}/{file_name}\"\n",
    "        # load each filename as image and resize the image to given target_size\n",
    "        image = load_img(filename, target_size=(299, 299))\n",
    "        # Convert image pixels to numpy array\n",
    "        image = img_to_array(image)\n",
    "        # Before presenting any data to CNN you may sometimes need to reshape your data\n",
    "        # We are reshaping the data without changing its content\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "        # Preparing the image to fit to the InceptionV3 model\n",
    "        image = preprocess_input(image)\n",
    "        # Extracting the features from the image\n",
    "        # By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
    "        # verbose=0 will show you nothing (silent)\n",
    "        # verbose=1 will show you an animated progress bar like this: [===============================]\n",
    "        # verbose=2 will just mention the number of epoch like this: Epoch 1/10\n",
    "        feature = model.predict(image, verbose=0)\n",
    "        # Getting the image id i.e. image12.jpg gets an image_id of image12\n",
    "        image_id = file_name.split('.')[0]\n",
    "        # Store the extracted feature to the empty 'features' dictionary created earlier\n",
    "        features[image_id] = feature\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8091 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8091/8091 [11:01<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all the extracted features is: 8091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = './Datasets/Flicker8k_Dataset'\n",
    "features = get_image_features(directory)\n",
    "print(\"The length of all the extracted features is:\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the features to pickle file\n",
    "dump(features, open('./InceptionV3_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vocabulary of Image Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to transform descriptions into sets\n",
    "# The set object is the vacabulary of all the words\n",
    "def create_vocabulary(description):\n",
    "    all_desc = set()\n",
    "    # Creating a list of words in description text and each word is added to set created above\n",
    "    for key in description.keys():\n",
    "        [all_desc.update(desc.split()) for desc in description[key]]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of descriptions: 8092\n",
      "The size of vocabulary is: 8763\n"
     ]
    }
   ],
   "source": [
    "# Calling the above created functions in a series\n",
    "filename = './Datasets/Flickr8k.token.txt'\n",
    "descriptions = read_image_descriptions(filename)\n",
    "print(f\"Total number of descriptions: {len(descriptions)}\")\n",
    "clean_description_text(descriptions)\n",
    "vocabulary = create_vocabulary(descriptions)\n",
    "print(f\"The size of vocabulary is: {len(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Descriptions of Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a predefined list of image identifiers\n",
    "# This function first creates the list of image identifiers and then convert them to set object\n",
    "def get_identifiers_set(filename):\n",
    "    # Read the text from given file\n",
    "    # Open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # Read all the text from the file\n",
    "    text = file.read()\n",
    "    # After reading the file completely close the file\n",
    "    file.close()\n",
    "    \n",
    "    identifiers = list()\n",
    "    # Iterate though each line using for loop\n",
    "    for line in text.split('\\n'):\n",
    "        # Skip empty lines in case they exist\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        # Grab the image identifier from each line and then add it to a list object created above\n",
    "        image_id = line.split('.')[0]\n",
    "        identifiers.append(image_id)\n",
    "    return set(identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to load pre-processed cleaned descriptions\n",
    "# We will read descriptions from 'InceptionV3_descriptions.txt' file created earlier\n",
    "def get_clean_descriptions(filename, identifiers):\n",
    "    # Read the text from given file\n",
    "    # Open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # Read all the text from the file\n",
    "    text = file.read()\n",
    "    # After reading the file completely close the file\n",
    "    file.close()\n",
    "    \n",
    "    descriptions = dict()\n",
    "    # Iterate though each line using for loop\n",
    "    for line in text.split('\\n'):\n",
    "        # Tokenize the lines by splitting them according to whitespaces\n",
    "        tokens = line.split()\n",
    "        # Separate image identifiers from their descriptions\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # Skip all the images that do not belong to the above create set of image identifiers\n",
    "        if image_id in identifiers:\n",
    "            # Since single image contains 5 descriptions, we should not repeat image_id for all 5 descriptions separately\n",
    "            # If image_id is inserted for first description, other 4 descriptions should be added to the same key\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = list()\n",
    "            # Wrap descriptions in tokens\n",
    "            # starttoken and endtoken are tokens to signal the start and end of the caption\n",
    "            # We need these tokens because the captions are generated one word at a time\n",
    "            # These tokens are added to descriptions as they are loaded\n",
    "            # Later we need to encode these descriptions in our walk through\n",
    "            # We need to add these texts before encoding the text so that these tokens also get encoded\n",
    "            desc = \"starttoken \" + ' '.join(image_desc) + \" endtoken\"\n",
    "            descriptions[image_id].append(desc)\n",
    "            \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the image features from the given dataset\n",
    "# filename argument is the pickle file (InceptionV3_features.pkl) that we created earlier\n",
    "# dataset argument is the training dataset\n",
    "def get_image_features(filename, dataset):\n",
    "    # Load all features\n",
    "    all_features = load(open(filename, 'rb'))\n",
    "    # Load features\n",
    "    features = {k: all_features[k] for k in dataset}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train identifiers is: 6000\n",
      "The length of train descriptions is: 6000\n",
      "The length of train features is: 6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['starttoken child in pink dress is climbing up set of stairs in an entry way endtoken',\n",
       " 'starttoken girl going into wooden building endtoken',\n",
       " 'starttoken little girl climbing into wooden playhouse endtoken',\n",
       " 'starttoken little girl climbing the stairs to her playhouse endtoken',\n",
       " 'starttoken little girl in pink dress going into wooden cabin endtoken']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training dataset (6000 out of 2000) as present in Flickr_8k.trainImages.txt\n",
    "filename = './Datasets/Flickr_8k.trainImages.txt'\n",
    "# Get identifiers of all the training images\n",
    "train_id = get_identifiers_set(filename)\n",
    "print(f\"The length of train identifiers is: {len(train_id)}\")\n",
    "# Get cleaned/pre-processed descriptions from the file saved earlier for the training images\n",
    "train_desc = get_clean_descriptions('./InceptionV3_descriptions.txt', train_id)\n",
    "print(f\"The length of train descriptions is: {len(train_desc)}\")\n",
    "# Get features of all the training images from the pickle file saved earlier\n",
    "train_features = get_image_features('./InceptionV3_features.pkl', train_id)\n",
    "print(f\"The length of train features is: {len(train_features)}\")\n",
    "# Print list of training descriptions for given image_id\n",
    "# train_desc is the dictionary of image_id that consists of list of descriptions for that image_id\n",
    "train_desc['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No machine learning model can operate with text based data as input. And so, here we will convert our text data to numerical data so that our model can understand this data. Inorder to encode the data we create the mapping of the words to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert dictionary of cleaned descriptions to list of cleaned descriptions\n",
    "def to_list(descriptions):\n",
    "    all_desc = list()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(one_of_five_desc) for one_of_five_desc in descriptions[key]]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to create tokens out of descriptions\n",
    "# i.e. Fucntion to tokenize the descriptions corpus\n",
    "def create_tokenizer(descriptions):\n",
    "    desc_list = to_list(descriptions)\n",
    "    # Keras has Tokenizer class that can learn the mapping of words to numerical values from loaded descriptions\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit_on_texts() method updates internal vocabulary based on a list of texts\n",
    "    # This method creates the vocabulary index based on word frequency\n",
    "    # So if you give it something like, \"The cat sat on the mat.\"\n",
    "    # It will create a dictionary s.t. word_index[\"the\"] = 1; word_index[\"cat\"] = 2\n",
    "    # So lower integer means more frequent word\n",
    "    # It is word -> index dictionary so every word gets a unique integer value. 0 is reserved for padding\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is: 7579\n"
     ]
    }
   ],
   "source": [
    "# Get the size of vocabulary\n",
    "tokenizer = create_tokenizer(train_desc)\n",
    "# Adding 1 to the length because indexing starts from zero\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"The size of the vocabulary is: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding/Mapping Descriptions to Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to calculate the length of the description having most words\n",
    "def max_lengths(descriptions):\n",
    "    desc_list = to_list(descriptions)\n",
    "    return max(len(desc.split()) for desc in desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to encode the text\n",
    "# Funtion to create a sequences of images, descriptions and outputs (next_words)\n",
    "def create_encoded_sequence(tokenizer, max_length, desc_list, image_feat):\n",
    "    # Instancing list objects to store image features, image descriptions and predicted next words\n",
    "    # Input text is encoded into numerical values\n",
    "    # So output text i.e predicted next word will also be one-hot encoded values\n",
    "    image_features, image_desc, next_words = list(), list(), list()\n",
    "    \n",
    "    # We'll iterate thorough each of the five descriptions of the given image using for loop\n",
    "    for desc in desc_list:\n",
    "        # texts_to_sequences() transforms each text in texts to a sequence of integers i.e. encode the sequence\n",
    "        # So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "        # Only top (num_words-1) most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        \n",
    "        # Using for loop to split one sequence to multiple x,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            # Split into input and output pairs\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # pad_sequences() is used to ensure that all sequences in a list have the same length.\n",
    "            # By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            # to_categorical() method that can be used to one-hot encode integer data.\n",
    "            # If the integer data represents all the possible values of the classes, then the to_categorical() method can be used directly\n",
    "            # Otherwise, the number of classes can be passed to the method as the num_classes parameter.\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            image_features.append(image_feat)\n",
    "            image_desc.append(in_seq)\n",
    "            next_words.append(out_seq)\n",
    "            \n",
    "    return np.array(image_features), np.array(image_desc), np.array(next_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging CNN based models with LSTM models together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have two different models: \n",
    "1. Sequence Processor (RNN/LSTM)\n",
    "2. Feature Extractor (CNN)\n",
    "\n",
    "Both Image Feature Extractor and Sequence Processor generate fixed length output vectors separately. These separate output vectors are passed though a common Decoder and get merged together. Here both the vectors are processed by a Dense layer to generate the image description output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Embedding, Dense\n",
    "from tensorflow.keras.layers import Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that houses the entire structure of our model\n",
    "def create_model(vocab_size, max_length):\n",
    "    # Sequence processor model\n",
    "    input1 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, 256, mask_zero=True)(input1)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "    seq3 = LSTM(256)(seq2)\n",
    "    \n",
    "    # Feature extractor model\n",
    "    input2 = Input(shape=(2048,))\n",
    "    feat1 = Dropout(0.5)(input2)\n",
    "    feat2 = Dense(256, activation='relu')(feat1)\n",
    "    \n",
    "    # Decoder model\n",
    "    decoder1 = Add()([feat2, seq3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    output = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    \n",
    "    # Tie all the image features and word sequence together using keras Model class\n",
    "    model = Model(inputs=[input2, input1], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load one image worth of data per batch\n",
    "def data_generator(descriptions, image_feats, tokenizer, max_length):\n",
    "    # while loop is used to go over each image\n",
    "    while 1:\n",
    "        # for loop is used to extract features for given image\n",
    "        for key, desc_list in descriptions.items():\n",
    "            # Retrive the image features\n",
    "            image_feat = image_feats[key][0]\n",
    "            # Create sequence for single image (not entire data) for given batch\n",
    "            image_features, desc, next_words = create_encoded_sequence(tokenizer, max_length, desc_list, image_feat)\n",
    "            # yield is used to return from a function without destroying the states of its local variable\n",
    "            # When the function is called, the execution starts from the last yield statement.\n",
    "            # Any function that contains a yield keyword is termed as generator\n",
    "            yield ([image_features, desc], next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train identifiers is: 6000\n",
      "The length of train descriptions is: 6000\n",
      "The length of train features is: 6000\n",
      "The size of the vocabulary is: 7579\n",
      "The maximum length of train descriptions is: 34\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset (6000 out of 2000) as present in Flickr_8k.trainImages.txt\n",
    "filename = './Datasets/Flickr_8k.trainImages.txt'\n",
    "# Get identifiers of all the training images\n",
    "train_id = get_identifiers_set(filename)\n",
    "print(f\"The length of train identifiers is: {len(train_id)}\")\n",
    "# Get cleaned/pre-processed descriptions from the file saved earlier for the training images\n",
    "train_desc = get_clean_descriptions('./InceptionV3_descriptions.txt', train_id)\n",
    "print(f\"The length of train descriptions is: {len(train_desc)}\")\n",
    "# Get features of all the training images from the pickle file saved earlier\n",
    "train_features = get_image_features('./InceptionV3_features.pkl', train_id)\n",
    "print(f\"The length of train features is: {len(train_features)}\")\n",
    "# Prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_desc)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"The size of the vocabulary is: {vocab_size}\")\n",
    "# Determine the maximum sequence length\n",
    "max_length = max_lengths(train_desc)\n",
    "print(f\"The maximum length of train descriptions is: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 34, 256)      1940224     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 34, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          525312      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7579)         1947803     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,003,675\n",
      "Trainable params: 5,003,675\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From <ipython-input-31-1ab10ceda16f>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "6000/6000 [==============================] - 568s 95ms/step - loss: 4.5204\n",
      "6000/6000 [==============================] - 563s 94ms/step - loss: 3.7131\n",
      "6000/6000 [==============================] - 556s 93ms/step - loss: 3.4469\n",
      "6000/6000 [==============================] - 549s 92ms/step - loss: 3.2844\n",
      "6000/6000 [==============================] - 545s 91ms/step - loss: 3.1709\n",
      "6000/6000 [==============================] - 546s 91ms/step - loss: 3.0869\n",
      "6000/6000 [==============================] - 545s 91ms/step - loss: 3.0223\n",
      "6000/6000 [==============================] - 543s 90ms/step - loss: 2.9710\n",
      "6000/6000 [==============================] - 541s 90ms/step - loss: 2.9295\n",
      "4033/6000 [===================>..........] - ETA: 2:57 - loss: 2.8913"
     ]
    }
   ],
   "source": [
    "# Here we will train the model and save our model after each epoch as .h5 filename begining with model_\n",
    "model = create_model(vocab_size, max_length)\n",
    "epochs = 10\n",
    "# Steps is the size of train descriptions\n",
    "steps = len(train_desc)\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Create data generator\n",
    "    generator = data_generator(train_desc, train_features, tokenizer, max_length)\n",
    "    model.fit_generator(generator=generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save(f\"./InceptionV3_Models/model_{i}.h5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Natural Language Processing, we may arise with multiple senarios where there may be multiple correct outputs. In such case, Accuracy Score is not a great metics to use and in those cases BLEU comes into paly.\n",
    "\n",
    "BLEU score stands for Bilingual Evaluation Understudy Score. BLEU, is a score for comparing a candidate translation of text to one or more reference translations. In simple language, BLEU Score is used to check how close the generated text is with respect to the expected text. Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks.\n",
    "\n",
    "The value of BLEU Score ranges from 0 to 1. Higher the BLEU Score, better will be the predicted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map a word using its corresponding word id\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        # Check if we have a match for given word at corresponding index\n",
    "        # If match found return the word else return None\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to generate a description for an image\n",
    "def generate_desc(model, tokenizer, image_feat, max_length):\n",
    "    # Seed/start the generation process\n",
    "    in_text = 'starttoken'\n",
    "    \n",
    "    # Iterate over the entire length of the sequence\n",
    "    # Here we will generate one word at a time by calling model recursively until 'END' string is detected\n",
    "    for i in range(max_length):\n",
    "        # Intiger encoded input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # Pad input\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # Predict next word\n",
    "        yhat = model.predict([image_feat, sequence], verbose=0)\n",
    "        # Concert probability to integer\n",
    "        yhat = np.argmax(yhat)\n",
    "        # Map integer to word\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        # Stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # Add the generated next word to the original sequence\n",
    "        in_text += \" \" + word\n",
    "        if word == 'endtoken':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the skill of the model\n",
    "# i.e. determine how good the model is\n",
    "def evaluate_model(model, descriptions, image_feat, tokenizer, max_length):\n",
    "    # Instancing two lists one to store actual description and next to store predicted descriptions\n",
    "    reference, candidate = list(), list()\n",
    "    \n",
    "    # Iterate for the entire set of images\n",
    "    for key, desc_list in tqdm(descriptions.items()):\n",
    "        # Generate descriptions\n",
    "        yhat = generate_desc(model, tokenizer, image_feat[key], max_length)\n",
    "        # Storing actual/reference and predicted/candidate descriptions\n",
    "        references = [desc.split() for desc in desc_list]\n",
    "        reference.append(references)\n",
    "        candidate.append(yhat.split())\n",
    "    \n",
    "    print(f\"Cumulative 1-gram: {corpus_bleu(reference, candidate, weights=(1,0,0,0))}\")\n",
    "    print(f\"Cumulative 2-gram: {corpus_bleu(reference, candidate, weights=(0.5,0.5,0,0))}\")\n",
    "    print(f\"Cumulative 3-gram: {corpus_bleu(reference, candidate, weights=(0.33,0.33,0.33,0))}\")\n",
    "    print(f\"Cumulative 4-gram: {corpus_bleu(reference, candidate, weights=(0.25,0.25,0.25,0.25))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train identifiers is: 6000\n",
      "The length of train descriptions is: 6000\n",
      "The size of the vocabulary is: 7579\n",
      "The maximum length of train descriptions is: 34\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset (6000 out of 2000) as present in Flickr_8k.trainImages.txt\n",
    "filename_train = './Datasets/Flickr_8k.trainImages.txt'\n",
    "# Get identifiers of all the training images\n",
    "train_id = get_identifiers_set(filename_train)\n",
    "print(f\"The length of train identifiers is: {len(train_id)}\")\n",
    "# Get cleaned/pre-processed descriptions from the file saved earlier for the training images\n",
    "train_desc = get_clean_descriptions('./InceptionV3_descriptions.txt', train_id)\n",
    "print(f\"The length of train descriptions is: {len(train_desc)}\")\n",
    "\n",
    "# Prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_desc)\n",
    "# Save all the features to pickle file\n",
    "dump(tokenizer, open('./InceptionV3_tokenizer.pkl', 'wb'))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"The size of the vocabulary is: {vocab_size}\")\n",
    "# Determine the maximum sequence length\n",
    "max_length = max_lengths(train_desc)\n",
    "print(f\"The maximum length of train descriptions is: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of test identifiers is: 1000\n",
      "The length of test descriptions is: 1000\n",
      "The length of test features is: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset (2000 out of 2000) as present in Flickr_8k.trainImages.txt\n",
    "filename_test = './Datasets/Flickr_8k.testImages.txt'\n",
    "# Get identifiers of all the test images\n",
    "test_id = get_identifiers_set(filename_test)\n",
    "print(f\"The length of test identifiers is: {len(test_id)}\")\n",
    "# Get cleaned/pre-processed descriptions from the file saved earlier for the test images\n",
    "test_desc = get_clean_descriptions('./InceptionV3_descriptions.txt', test_id)\n",
    "print(f\"The length of test descriptions is: {len(test_desc)}\")\n",
    "\n",
    "# Load test image features\n",
    "test_features = get_image_features('./InceptionV3_features.pkl', test_id)\n",
    "print(f\"The length of test features is: {len(test_desc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:27<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative 1-gram: 0.52\n",
      "Cumulative 2-gram: 0.27882658104112307\n",
      "Cumulative 3-gram: 0.1629873472384631\n",
      "Cumulative 4-gram: 0.09018026878364217\n"
     ]
    }
   ],
   "source": [
    "# Load the model which has minimum loss\n",
    "# Here I am working with model_8.h5\n",
    "filename = './InceptionV3_Models/model_8.h5'\n",
    "model = load_model(filename)\n",
    "# Evaluate model\n",
    "evaluate_model(model, test_desc, test_features, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Image Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to extract features from each image to the directory\n",
    "def extract_test_features(filename):\n",
    "    # Create an instance of the InceptionV3 model\n",
    "    model = InceptionV3()\n",
    "    # Restructuring our InceptionV3 model by removing/Popping off the last layer of the model\n",
    "    # The last layer is used to classify the images. Since we are not classifying images here, we're removing the last layer\n",
    "    model.layers.pop()\n",
    "    # Keras model represents the actual neural network model.\n",
    "    # Keras provides a two mode to create the model, simple and easy to use Sequential API as well as more flexible and advanced Functional API.\n",
    "    # A ANN model can be created by simply calling Sequential() API\n",
    "    # Sequential API is used to create models layer-by-layer\n",
    "    # Functional model, you can define multiple input or output that share layers.\n",
    "    # First, we create an instance for model using Model class and connect to the layers to access input and output to the model\n",
    "    # model.inputs is the input fed to the model and model.layers[-1].output is the output of the last(-1) layer of the model\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "    # load each filename as image and resize the image to given target_size\n",
    "    image = load_img(filename, target_size=(299, 299))\n",
    "    # Convert image pixels to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # Before presenting any data to CNN you may sometimes need to reshape your data\n",
    "    # We are reshaping the data without changing its content\n",
    "    image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "    # Preparing the image to fit to the InceptionV3 model\n",
    "    image = preprocess_input(image)\n",
    "    # Extracting the features from the image\n",
    "    # By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
    "    # verbose=0 will show you nothing (silent)\n",
    "    # verbose=1 will show you an animated progress bar like this: [===============================]\n",
    "    # verbose=2 will just mention the number of epoch like this: Epoch 1/10\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starttoken man in red shirt is riding bike down the street endtoken\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load(open('InceptionV3_tokenizer.pkl', 'rb'))\n",
    "# Pre-define the maximum sequence length (from taining)\n",
    "max_length = 34\n",
    "# Load the model with minimum error\n",
    "model = load_model('./InceptionV3_Models/model_8.h5')\n",
    "# Load the image of which you need to generate description\n",
    "test_image = extract_test_features('./cycle.jpg')\n",
    "# Generate description of the image\n",
    "description = generate_desc(model, tokenizer, test_image, max_length)\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man in red shirt is riding bike down the street\n"
     ]
    }
   ],
   "source": [
    "# Remove start and end tokens\n",
    "query = description\n",
    "stopwords = ['starttoken', 'endtoken']\n",
    "query_words = query.split()\n",
    "result = [word for word in query_words if word not in stopwords]\n",
    "result = ' '.join(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
